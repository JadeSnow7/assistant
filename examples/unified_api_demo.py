"""
ç»Ÿä¸€APIç³»ç»Ÿæ¼”ç¤ºè„šæœ¬
"""
import asyncio
import json
import os
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
import sys
sys.path.append('/home/snow/workspace/nex/python')

from core.adapters import UnifiedChatRequest, ProviderType
from core.unified_api_gateway import UnifiedAPIGateway
from core.config_manager import initialize_config_manager, get_config


async def demo_basic_chat():
    """æ¼”ç¤ºåŸºæœ¬èŠå¤©åŠŸèƒ½"""
    print("ğŸ”¹ æ¼”ç¤ºåŸºæœ¬èŠå¤©åŠŸèƒ½")
    
    # åˆ›å»ºèŠå¤©è¯·æ±‚
    request = UnifiedChatRequest(
        model="auto",  # è‡ªåŠ¨é€‰æ‹©æ¨¡å‹
        messages=[
            {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±"}
        ],
        max_tokens=200,
        temperature=0.7
    )
    
    # åˆ›å»ºç½‘å…³å®ä¾‹
    gateway = UnifiedAPIGateway()
    
    try:
        # åˆå§‹åŒ–ç½‘å…³
        print("  æ­£åœ¨åˆå§‹åŒ–APIç½‘å…³...")
        success = await gateway.initialize()
        
        if not success:
            print("  âš ï¸ ç½‘å…³åˆå§‹åŒ–å¤±è´¥ï¼Œä½†ç»§ç»­æ¼”ç¤º")
        
        # å¤„ç†èŠå¤©è¯·æ±‚
        print("  æ­£åœ¨å¤„ç†èŠå¤©è¯·æ±‚...")
        response = await gateway.handle_chat_completion(request)
        
        # è¾“å‡ºç»“æœ
        print(f"  âœ… å“åº”æˆåŠŸ")
        print(f"  ğŸ“ ä½¿ç”¨æ¨¡å‹: {response.model} ({response.provider})")
        print(f"  ğŸ’¬ å›å¤å†…å®¹: {response.choices[0]['message']['content'][:100]}...")
        
        if response.usage:
            print(f"  ğŸ“Š Tokenä½¿ç”¨: {response.usage['total_tokens']} tokens")
        
        if response.performance:
            print(f"  âš¡ å“åº”æ—¶é—´: {response.performance['latency_ms']:.0f}ms")
    
    except Exception as e:
        print(f"  âŒ æ¼”ç¤ºå¤±è´¥: {e}")
    
    finally:
        await gateway.cleanup()


async def demo_model_selection():
    """æ¼”ç¤ºæ¨¡å‹é€‰æ‹©åŠŸèƒ½"""
    print("\nğŸ”¹ æ¼”ç¤ºæ¨¡å‹é€‰æ‹©åŠŸèƒ½")
    
    gateway = UnifiedAPIGateway()
    
    try:
        await gateway.initialize()
        
        # æµ‹è¯•ä¸åŒçš„æ¨¡å‹é€‰æ‹©
        test_cases = [
            {
                "provider": "auto",
                "model": "auto",
                "message": "ç®€å•é—®å€™ï¼šä½ å¥½",
                "description": "è‡ªåŠ¨é€‰æ‹©ï¼ˆç®€å•ä»»åŠ¡ï¼‰"
            },
            {
                "provider": "auto", 
                "model": "auto",
                "message": "å¤æ‚ä»»åŠ¡ï¼šè¯·è¯¦ç»†åˆ†æäººå·¥æ™ºèƒ½çš„å‘å±•è¶‹åŠ¿ï¼ŒåŒ…æ‹¬æŠ€æœ¯æŒ‘æˆ˜å’Œæœºé‡",
                "description": "è‡ªåŠ¨é€‰æ‹©ï¼ˆå¤æ‚ä»»åŠ¡ï¼‰"
            }
        ]
        
        for i, case in enumerate(test_cases):
            print(f"\n  æµ‹è¯• {i+1}: {case['description']}")
            print(f"  ğŸ“ è¾“å…¥: {case['message'][:50]}...")
            
            request = UnifiedChatRequest(
                model=case["model"],
                messages=[{"role": "user", "content": case["message"]}],
                provider=case["provider"],
                max_tokens=100
            )
            
            response = await gateway.handle_chat_completion(request)
            print(f"  ğŸ¯ é€‰æ‹©æ¨¡å‹: {response.model} ({response.provider})")
            
            # å¦‚æœæœ‰æ€§èƒ½æ•°æ®ï¼Œæ˜¾ç¤º
            if response.performance:
                latency = response.performance.get('latency_ms', 0)
                print(f"  âš¡ å“åº”æ—¶é—´: {latency:.0f}ms")
    
    except Exception as e:
        print(f"  âŒ æ¼”ç¤ºå¤±è´¥: {e}")
    
    finally:
        await gateway.cleanup()


async def demo_available_models():
    """æ¼”ç¤ºå¯ç”¨æ¨¡å‹æŸ¥è¯¢"""
    print("\nğŸ”¹ æ¼”ç¤ºå¯ç”¨æ¨¡å‹æŸ¥è¯¢")
    
    gateway = UnifiedAPIGateway()
    
    try:
        await gateway.initialize()
        
        print("  æ­£åœ¨æŸ¥è¯¢å¯ç”¨æ¨¡å‹...")
        models_response = await gateway.list_available_models()
        
        models = models_response.get("data", [])
        
        if models:
            print(f"  âœ… æ‰¾åˆ° {len(models)} ä¸ªå¯ç”¨æ¨¡å‹:")
            
            # æŒ‰æä¾›å•†åˆ†ç»„æ˜¾ç¤º
            providers = {}
            for model in models:
                provider = model.get("provider", "unknown")
                if provider not in providers:
                    providers[provider] = []
                providers[provider].append(model)
            
            for provider, provider_models in providers.items():
                print(f"\n    ğŸ“¡ {provider.upper()}:")
                for model in provider_models:
                    status_emoji = "âœ…" if model.get("status") == "available" else "âŒ"
                    context_length = model.get("context_length", 0)
                    print(f"      {status_emoji} {model['id']} (ä¸Šä¸‹æ–‡: {context_length} tokens)")
        else:
            print("  âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨æ¨¡å‹")
    
    except Exception as e:
        print(f"  âŒ æŸ¥è¯¢å¤±è´¥: {e}")
    
    finally:
        await gateway.cleanup()


async def demo_engine_status():
    """æ¼”ç¤ºå¼•æ“çŠ¶æ€æŸ¥è¯¢"""
    print("\nğŸ”¹ æ¼”ç¤ºå¼•æ“çŠ¶æ€æŸ¥è¯¢")
    
    gateway = UnifiedAPIGateway()
    
    try:
        await gateway.initialize()
        
        print("  æ­£åœ¨æŸ¥è¯¢å¼•æ“çŠ¶æ€...")
        status_response = await gateway.get_engines_status()
        
        engines = status_response.get("engines", {})
        
        if engines:
            print(f"  âœ… æ‰¾åˆ° {len(engines)} ä¸ªå¼•æ“:")
            
            for engine_name, engine_status in engines.items():
                status = engine_status.get("status", "unknown")
                status_emoji = "âœ…" if status == "healthy" else "âŒ" if status == "error" else "âš ï¸"
                
                print(f"\n    {status_emoji} {engine_name.upper()} ({engine_status.get('provider', 'unknown')})")
                print(f"      çŠ¶æ€: {status}")
                
                models_loaded = engine_status.get("models_loaded", [])
                if models_loaded:
                    print(f"      å·²åŠ è½½æ¨¡å‹: {', '.join(models_loaded)}")
                
                if engine_status.get("memory_usage_mb"):
                    print(f"      å†…å­˜ä½¿ç”¨: {engine_status['memory_usage_mb']:.0f}MB")
                
                if engine_status.get("gpu_utilization"):
                    print(f"      GPUä½¿ç”¨ç‡: {engine_status['gpu_utilization']:.1f}%")
                
                if engine_status.get("error"):
                    print(f"      é”™è¯¯: {engine_status['error']}")
        else:
            print("  âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¼•æ“ä¿¡æ¯")
    
    except Exception as e:
        print(f"  âŒ æŸ¥è¯¢å¤±è´¥: {e}")
    
    finally:
        await gateway.cleanup()


async def demo_performance_stats():
    """æ¼”ç¤ºæ€§èƒ½ç»Ÿè®¡"""
    print("\nğŸ”¹ æ¼”ç¤ºæ€§èƒ½ç»Ÿè®¡")
    
    gateway = UnifiedAPIGateway()
    
    try:
        await gateway.initialize()
        
        # å…ˆå‘é€å‡ ä¸ªè¯·æ±‚æ¥ç”Ÿæˆç»Ÿè®¡æ•°æ®
        print("  æ­£åœ¨ç”Ÿæˆç»Ÿè®¡æ•°æ®...")
        
        test_messages = [
            "ä½ å¥½",
            "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
            "è§£é‡Šä¸€ä¸‹äººå·¥æ™ºèƒ½"
        ]
        
        for msg in test_messages:
            request = UnifiedChatRequest(
                model="auto",
                messages=[{"role": "user", "content": msg}],
                max_tokens=50
            )
            try:
                await gateway.handle_chat_completion(request)
            except:
                pass  # å¿½ç•¥é”™è¯¯ï¼Œç»§ç»­ç»Ÿè®¡
        
        # è·å–æ€§èƒ½ç»Ÿè®¡
        print("  æ­£åœ¨è·å–æ€§èƒ½ç»Ÿè®¡...")
        stats_response = await gateway.get_performance_stats()
        
        # æ˜¾ç¤ºAPIç½‘å…³ç»Ÿè®¡
        api_stats = stats_response.get("api_gateway", {})
        print(f"\n  ğŸ“Š APIç½‘å…³ç»Ÿè®¡:")
        print(f"    æ€»è¯·æ±‚æ•°: {api_stats.get('total_requests', 0)}")
        print(f"    æˆåŠŸè¯·æ±‚: {api_stats.get('successful_requests', 0)}")
        print(f"    å¤±è´¥è¯·æ±‚: {api_stats.get('failed_requests', 0)}")
        print(f"    å¹³å‡å»¶è¿Ÿ: {api_stats.get('avg_latency', 0):.0f}ms")
        
        # æ˜¾ç¤ºæŒ‰æä¾›å•†çš„è¯·æ±‚åˆ†å¸ƒ
        provider_stats = api_stats.get("requests_by_provider", {})
        if provider_stats:
            print(f"\n  ğŸ“ˆ è¯·æ±‚åˆ†å¸ƒ:")
            for provider, count in provider_stats.items():
                print(f"    {provider}: {count} æ¬¡")
        
        # æ˜¾ç¤ºGPUä¿¡æ¯
        gpu_info = stats_response.get("gpu_info", [])
        if gpu_info:
            print(f"\n  ğŸ® GPUä¿¡æ¯:")
            for gpu in gpu_info:
                print(f"    GPU {gpu.get('id', 0)}: {gpu.get('name', 'Unknown')}")
                print(f"      ä½¿ç”¨ç‡: {gpu.get('utilization', 0):.1f}%")
                print(f"      æ˜¾å­˜: {gpu.get('memory_used', 0)}/{gpu.get('memory_total', 0)}MB")
    
    except Exception as e:
        print(f"  âŒ æ¼”ç¤ºå¤±è´¥: {e}")
    
    finally:
        await gateway.cleanup()


async def demo_configuration():
    """æ¼”ç¤ºé…ç½®ç®¡ç†"""
    print("\nğŸ”¹ æ¼”ç¤ºé…ç½®ç®¡ç†")
    
    try:
        # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        print("  æ­£åœ¨åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨...")
        await initialize_config_manager()
        
        # è·å–å½“å‰é…ç½®
        print("  æ­£åœ¨è·å–å½“å‰é…ç½®...")
        config = get_config()
        
        if config:
            print("  âœ… é…ç½®åŠ è½½æˆåŠŸ")
            
            # æ˜¾ç¤ºAPIé…ç½®
            api_config = config.get("api", {})
            print(f"\n  ğŸŒ APIé…ç½®:")
            print(f"    ä¸»æœº: {api_config.get('host', 'unknown')}")
            print(f"    ç«¯å£: {api_config.get('port', 'unknown')}")
            
            # æ˜¾ç¤ºå¯ç”¨çš„å¼•æ“
            engines_config = config.get("engines", {})
            enabled_engines = [name for name, cfg in engines_config.items() 
                             if cfg.get("enabled", False)]
            
            print(f"\n  ğŸ”§ å¯ç”¨çš„å¼•æ“: {', '.join(enabled_engines) if enabled_engines else 'æ— '}")
            
            # æ˜¾ç¤ºGPUé…ç½®
            gpu_config = config.get("gpu", {})
            print(f"\n  ğŸ® GPUé…ç½®:")
            print(f"    å¯ç”¨: {gpu_config.get('enabled', False)}")
            print(f"    GPUå±‚æ•°: {gpu_config.get('gpu_layers', 0)}")
            print(f"    è‡ªåŠ¨æ£€æµ‹: {gpu_config.get('auto_detect', False)}")
            
            # æ˜¾ç¤ºè·¯ç”±é…ç½®
            routing_config = config.get("routing", {})
            print(f"\n  ğŸ§­ è·¯ç”±é…ç½®:")
            print(f"    ç­–ç•¥: {routing_config.get('strategy', 'unknown')}")
            print(f"    æœ¬åœ°åå¥½: {routing_config.get('local_preference', 0)}")
            print(f"    å¤æ‚åº¦é˜ˆå€¼: {routing_config.get('complexity_threshold', 0)}")
        else:
            print("  âš ï¸ é…ç½®ä¸ºç©ºæˆ–åŠ è½½å¤±è´¥")
    
    except Exception as e:
        print(f"  âŒ é…ç½®æ¼”ç¤ºå¤±è´¥: {e}")


async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ ç»Ÿä¸€APIç³»ç»Ÿæ¼”ç¤º")
    print("=" * 50)
    
    # è®¾ç½®å¿…è¦çš„ç¯å¢ƒå˜é‡ï¼ˆæ¼”ç¤ºç”¨ï¼‰
    if not os.getenv("OPENAI_API_KEY"):
        os.environ["OPENAI_API_KEY"] = "demo_key_not_real"
    if not os.getenv("GEMINI_API_KEY"):
        os.environ["GEMINI_API_KEY"] = "demo_key_not_real"
    
    try:
        # è¿è¡Œå„ä¸ªæ¼”ç¤º
        await demo_configuration()
        await demo_available_models()
        await demo_engine_status()
        await demo_basic_chat()
        await demo_model_selection()
        await demo_performance_stats()
        
        print("\n" + "=" * 50)
        print("âœ… æ¼”ç¤ºå®Œæˆï¼")
        print("\nğŸ“ æ€»ç»“:")
        print("  - ç»Ÿä¸€APIæ¥å£æ”¯æŒå¤šç§æ¨¡å‹å¼•æ“")
        print("  - æ™ºèƒ½è·¯ç”±æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©æœ€ä¼˜æ¨¡å‹")
        print("  - åŠ¨æ€é…ç½®ç®¡ç†æ”¯æŒå®æ—¶æ›´æ–°")
        print("  - GPUåŠ é€Ÿè‡ªåŠ¨æ£€æµ‹å’Œé…ç½®")
        print("  - å®Œæ•´çš„æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡")
    
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == "__main__":
    asyncio.run(main())