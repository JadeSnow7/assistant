#!/usr/bin/env python3
"""
æ™ºèƒ½è·¯ç”±å†³ç­–éªŒè¯æµ‹è¯•å¥—ä»¶
æµ‹è¯•æœ¬åœ°/äº‘ç«¯æ¨¡å‹é€‰æ‹©é€»è¾‘ï¼ŒéªŒè¯AIä»»åŠ¡åŠ¨æ€è·¯ç”±ç­–ç•¥
"""
import asyncio
import time
from typing import List, Dict, Any, Optional
from tests.unit.base import BaseTestSuite, TestCase, TestResult, TestMetrics, PerformanceTestMixin


class IntelligentRoutingTestSuite(BaseTestSuite, PerformanceTestMixin):
    """æ™ºèƒ½è·¯ç”±å†³ç­–æµ‹è¯•å¥—ä»¶"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        super().__init__(base_url)
        self.routing_test_cases = self._create_routing_test_cases()
    
    def _create_routing_test_cases(self) -> List[TestCase]:
        """åˆ›å»ºè·¯ç”±å†³ç­–æµ‹è¯•ç”¨ä¾‹"""
        return [
            # ç®€å•ä»»åŠ¡ - åº”è¯¥ä½¿ç”¨æœ¬åœ°æ¨¡å‹
            TestCase(
                name="simple_greeting_routing",
                description="ç®€å•é—®å€™åº”è¯¥è·¯ç”±åˆ°æœ¬åœ°æ¨¡å‹",
                input_data={
                    "message": "ä½ å¥½",
                    "expected_route": "local",
                    "complexity": "simple",
                    "max_time": 1000
                },
                expected_output={"model_type": "local", "fast_response": True},
                category="ç®€å•ä»»åŠ¡è·¯ç”±",
                priority="HIGH"
            ),
            TestCase(
                name="basic_qa_routing",
                description="åŸºç¡€é—®ç­”åº”è¯¥è·¯ç”±åˆ°æœ¬åœ°æ¨¡å‹",
                input_data={
                    "message": "ä»€ä¹ˆæ˜¯Pythonï¼Ÿ",
                    "expected_route": "local",
                    "complexity": "simple",
                    "max_time": 1500
                },
                expected_output={"model_type": "local", "accurate_response": True},
                category="ç®€å•ä»»åŠ¡è·¯ç”±",
                priority="HIGH"
            ),
            TestCase(
                name="simple_calculation",
                description="ç®€å•è®¡ç®—åº”è¯¥è·¯ç”±åˆ°æœ¬åœ°æ¨¡å‹",
                input_data={
                    "message": "1+1ç­‰äºå¤šå°‘ï¼Ÿ",
                    "expected_route": "local", 
                    "complexity": "simple",
                    "max_time": 800
                },
                expected_output={"model_type": "local", "correct_answer": True},
                category="ç®€å•ä»»åŠ¡è·¯ç”±",
                priority="MEDIUM"
            ),
            
            # å¤æ‚ä»»åŠ¡ - åº”è¯¥ä½¿ç”¨äº‘ç«¯æ¨¡å‹
            TestCase(
                name="complex_analysis_routing",
                description="å¤æ‚åˆ†æåº”è¯¥è·¯ç”±åˆ°äº‘ç«¯æ¨¡å‹",
                input_data={
                    "message": "åˆ†æäººå·¥æ™ºèƒ½å¯¹æœªæ¥åŠ³åŠ¨åŠ›å¸‚åœºçš„æ·±å±‚å½±å“ï¼ŒåŒ…æ‹¬æŠ€æœ¯å‘å±•è¶‹åŠ¿ã€æ”¿ç­–å»ºè®®å’Œç¤¾ä¼šé€‚åº”ç­–ç•¥",
                    "expected_route": "cloud",
                    "complexity": "complex",
                    "max_time": 10000
                },
                expected_output={"model_type": "cloud", "comprehensive_analysis": True},
                category="å¤æ‚ä»»åŠ¡è·¯ç”±",
                priority="HIGH"
            ),
            TestCase(
                name="creative_writing_routing",
                description="åˆ›æ„å†™ä½œåº”è¯¥è·¯ç”±åˆ°äº‘ç«¯æ¨¡å‹",
                input_data={
                    "message": "å†™ä¸€ä¸ªå…³äºæ—¶é—´æ—…è¡Œçš„ç§‘å¹»å°è¯´å¼€å¤´ï¼Œè¦æ±‚æƒ…èŠ‚æ–°é¢–ï¼Œäººç‰©ç”ŸåŠ¨ï¼Œè¯­è¨€ä¼˜ç¾",
                    "expected_route": "cloud",
                    "complexity": "complex",
                    "max_time": 15000
                },
                expected_output={"model_type": "cloud", "creative_content": True},
                category="å¤æ‚ä»»åŠ¡è·¯ç”±",
                priority="MEDIUM"
            ),
            TestCase(
                name="technical_architecture_routing",
                description="æŠ€æœ¯æ¶æ„è®¾è®¡åº”è¯¥è·¯ç”±åˆ°äº‘ç«¯æ¨¡å‹",
                input_data={
                    "message": "è®¾è®¡ä¸€ä¸ªæ”¯æŒåƒä¸‡çº§ç”¨æˆ·çš„åˆ†å¸ƒå¼ç¤¾äº¤åª’ä½“ç³»ç»Ÿæ¶æ„ï¼ŒåŒ…æ‹¬æ•°æ®åº“è®¾è®¡ã€ç¼“å­˜ç­–ç•¥ã€è´Ÿè½½å‡è¡¡å’Œå®‰å…¨è€ƒè™‘",
                    "expected_route": "cloud",
                    "complexity": "complex",
                    "max_time": 12000
                },
                expected_output={"model_type": "cloud", "detailed_design": True},
                category="å¤æ‚ä»»åŠ¡è·¯ç”±",
                priority="HIGH"
            ),
            
            # ä¸­ç­‰å¤æ‚åº¦ä»»åŠ¡ - æ™ºèƒ½è·¯ç”±
            TestCase(
                name="code_review_routing",
                description="ä»£ç å®¡æŸ¥ä»»åŠ¡çš„æ™ºèƒ½è·¯ç”±",
                input_data={
                    "message": "è¯·å®¡æŸ¥è¿™æ®µPythonä»£ç å¹¶æå‡ºæ”¹è¿›å»ºè®®ï¼šdef add(a, b): return a + b",
                    "expected_route": "auto",
                    "complexity": "medium",
                    "max_time": 3000
                },
                expected_output={"appropriate_route": True, "quality_feedback": True},
                category="æ™ºèƒ½è·¯ç”±",
                priority="MEDIUM"
            ),
            TestCase(
                name="explanation_routing",
                description="æŠ€æœ¯æ¦‚å¿µè§£é‡Šçš„æ™ºèƒ½è·¯ç”±",
                input_data={
                    "message": "è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯å¾®æœåŠ¡æ¶æ„ï¼ŒåŒ…æ‹¬ä¼˜ç¼ºç‚¹",
                    "expected_route": "auto",
                    "complexity": "medium",
                    "max_time": 4000
                },
                expected_output={"appropriate_route": True, "comprehensive_explanation": True},
                category="æ™ºèƒ½è·¯ç”±",
                priority="MEDIUM"
            ),
            
            # æ’ä»¶è·¯ç”±æµ‹è¯•
            TestCase(
                name="weather_plugin_routing",
                description="å¤©æ°”æŸ¥è¯¢åº”è¯¥è·¯ç”±åˆ°å¤©æ°”æ’ä»¶",
                input_data={
                    "message": "ä¸Šæµ·æ˜å¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
                    "expected_route": "plugin",
                    "expected_plugin": "weather",
                    "max_time": 5000
                },
                expected_output={"plugin_used": True, "weather_data": True},
                category="æ’ä»¶è·¯ç”±",
                priority="HIGH"
            ),
            TestCase(
                name="system_command_routing",
                description="ç³»ç»Ÿå‘½ä»¤åº”è¯¥è·¯ç”±åˆ°ç³»ç»Ÿæ’ä»¶",
                input_data={
                    "message": "æŸ¥çœ‹å½“å‰ç³»ç»ŸCPUä½¿ç”¨æƒ…å†µ",
                    "expected_route": "plugin", 
                    "expected_plugin": "system",
                    "max_time": 3000
                },
                expected_output={"plugin_used": True, "system_info": True},
                category="æ’ä»¶è·¯ç”±",
                priority="MEDIUM"
            ),
            
            # è´Ÿè½½å‡è¡¡æµ‹è¯•
            TestCase(
                name="load_balance_routing",
                description="é«˜è´Ÿè½½æ—¶çš„è´Ÿè½½å‡è¡¡è·¯ç”±",
                input_data={
                    "message": "è§£é‡Šé‡å­è®¡ç®—çš„åŸºæœ¬åŸç†",
                    "expected_route": "auto",
                    "simulate_high_load": True,
                    "max_time": 8000
                },
                expected_output={"load_balanced": True, "reasonable_response_time": True},
                category="è´Ÿè½½å‡è¡¡",
                priority="MEDIUM"
            ),
            
            # èµ„æºé™åˆ¶æµ‹è¯•
            TestCase(
                name="resource_constraint_routing",
                description="èµ„æºå—é™æ—¶çš„è·¯ç”±å†³ç­–",
                input_data={
                    "message": "å¸®æˆ‘å†™ä¸€ä¸ªå¤æ‚çš„ç®—æ³•å®ç°",
                    "expected_route": "auto",
                    "simulate_resource_constraint": True,
                    "max_time": 6000
                },
                expected_output={"resource_aware": True, "alternative_route": True},
                category="èµ„æºçº¦æŸ",
                priority="MEDIUM"
            )
        ]
    
    async def run_test_case(self, test_case: TestCase):
        """è¿è¡Œå•ä¸ªè·¯ç”±æµ‹è¯•ç”¨ä¾‹"""
        try:
            if test_case.category in ["ç®€å•ä»»åŠ¡è·¯ç”±", "å¤æ‚ä»»åŠ¡è·¯ç”±"]:
                await self._test_complexity_based_routing(test_case)
            elif test_case.category == "æ™ºèƒ½è·¯ç”±":
                await self._test_intelligent_routing(test_case)
            elif test_case.category == "æ’ä»¶è·¯ç”±":
                await self._test_plugin_routing(test_case)
            elif test_case.category == "è´Ÿè½½å‡è¡¡":
                await self._test_load_balance_routing(test_case)
            elif test_case.category == "èµ„æºçº¦æŸ":
                await self._test_resource_constraint_routing(test_case)
            else:
                self.record_test_result(test_case, TestResult.SKIP,
                                      details={"error": f"æœªçŸ¥è·¯ç”±æµ‹è¯•ç±»åˆ«: {test_case.category}"})
                
        except Exception as e:
            self.record_test_result(test_case, TestResult.ERROR,
                                  details={"error": f"è·¯ç”±æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {str(e)}"})
    
    async def _test_complexity_based_routing(self, test_case: TestCase):
        """æµ‹è¯•åŸºäºå¤æ‚åº¦çš„è·¯ç”±å†³ç­–"""
        message = test_case.input_data["message"]
        expected_route = test_case.input_data["expected_route"]
        complexity = test_case.input_data["complexity"]
        max_time = test_case.input_data["max_time"]
        
        # å‘é€è¯·æ±‚
        result = await self.send_chat_request(message)
        
        if "error" in result:
            self.record_test_result(test_case, TestResult.FAIL,
                                  details={"error": result["error"]})
            return
        
        # åˆ†æè·¯ç”±å†³ç­–
        model_used = result.get("model_used", "").lower()
        reasoning = result.get("reasoning", "").lower()
        response_time = result.get("_response_time_ms", 0)
        
        # éªŒè¯è·¯ç”±å†³ç­–
        route_correct = False
        
        if expected_route == "local":
            # ç®€å•ä»»åŠ¡åº”è¯¥ä½¿ç”¨æœ¬åœ°æ¨¡å‹
            route_correct = any(indicator in model_used for indicator in ["local", "qwen", "ollama"])
            if not route_correct:
                # æ£€æŸ¥æ¨ç†è¿‡ç¨‹ä¸­çš„è·¯ç”±åŸå› 
                route_correct = any(indicator in reasoning for indicator in ["æœ¬åœ°", "ç®€å•", "å¿«é€Ÿ"])
        
        elif expected_route == "cloud":
            # å¤æ‚ä»»åŠ¡åº”è¯¥ä½¿ç”¨äº‘ç«¯æ¨¡å‹
            route_correct = any(indicator in model_used for indicator in ["cloud", "gemini", "gpt"])
            if not route_correct:
                route_correct = any(indicator in reasoning for indicator in ["äº‘ç«¯", "å¤æ‚", "è¯¦ç»†"])
        
        if not route_correct:
            self.record_test_result(test_case, TestResult.FAIL,
                                  details={
                                      "error": f"è·¯ç”±å†³ç­–é”™è¯¯: æœŸæœ›{expected_route}, å®é™…ä½¿ç”¨{model_used}",
                                      "reasoning": reasoning
                                  })
            return
        
        # éªŒè¯å“åº”è´¨é‡
        content = result.get("content", "")
        quality_ok = True
        
        if complexity == "simple":
            # ç®€å•ä»»åŠ¡åº”è¯¥å¿«é€Ÿå“åº”
            if response_time > max_time:
                quality_ok = False
                self.logger.warning(f"ç®€å•ä»»åŠ¡å“åº”æ—¶é—´è¿‡é•¿: {response_time}ms > {max_time}ms")
        
        elif complexity == "complex":
            # å¤æ‚ä»»åŠ¡åº”è¯¥æœ‰è¯¦ç»†å›ç­”
            if len(content) < 100:
                quality_ok = False
                self.logger.warning(f"å¤æ‚ä»»åŠ¡å›ç­”è¿‡äºç®€çŸ­: {len(content)} chars")
        
        # è®°å½•ç»“æœ
        performance_ok = self.assert_performance(response_time, max_time, test_case.name)
        
        metrics = TestMetrics(
            response_time_ms=response_time,
            token_count=result.get("token_count", 0),
            model_used=model_used,
            memory_usage_mb=0.0,
            cpu_usage_percent=0.0,
            success=route_correct and quality_ok
        )
        
        test_result = TestResult.PASS if (route_correct and quality_ok) else TestResult.FAIL
        
        self.record_test_result(test_case, test_result, metrics=metrics,
                              details={
                                  "route_correct": route_correct,
                                  "quality_ok": quality_ok,
                                  "performance_ok": performance_ok,
                                  "complexity": complexity,
                                  "actual_model": model_used
                              })
    
    async def _test_intelligent_routing(self, test_case: TestCase):
        """æµ‹è¯•æ™ºèƒ½è·¯ç”±å†³ç­–"""
        message = test_case.input_data["message"]
        max_time = test_case.input_data["max_time"]
        
        result = await self.send_chat_request(message)
        
        if "error" in result:
            self.record_test_result(test_case, TestResult.FAIL,
                                  details={"error": result["error"]})
            return
        
        model_used = result.get("model_used", "")
        reasoning = result.get("reasoning", "")
        content = result.get("content", "")
        response_time = result.get("_response_time_ms", 0)
        
        # æ™ºèƒ½è·¯ç”±è¯„ä¼°æ ‡å‡†
        route_appropriate = True
        quality_assessment = {}
        
        # æ£€æŸ¥è·¯ç”±åˆç†æ€§
        if "ä»£ç " in message or "code" in message.lower():
            # ä»£ç ç›¸å…³ä»»åŠ¡ï¼Œæ£€æŸ¥å›ç­”è´¨é‡
            if len(content) < 50:
                route_appropriate = False
                quality_assessment["code_quality"] = "insufficient"
            else:
                quality_assessment["code_quality"] = "adequate"
        
        elif "è§£é‡Š" in message or "explain" in message.lower():
            # è§£é‡Šä»»åŠ¡ï¼Œæ£€æŸ¥è§£é‡Šçš„å®Œæ•´æ€§
            if len(content) < 80:
                route_appropriate = False
                quality_assessment["explanation_quality"] = "insufficient"
            else:
                quality_assessment["explanation_quality"] = "comprehensive"
        
        # æ£€æŸ¥å†³ç­–æ¨ç†
        has_reasoning = len(reasoning) > 10
        quality_assessment["has_reasoning"] = has_reasoning
        
        performance_ok = self.assert_performance(response_time, max_time, test_case.name)
        
        metrics = TestMetrics(
            response_time_ms=response_time,
            token_count=result.get("token_count", 0),
            model_used=model_used,
            memory_usage_mb=0.0,
            cpu_usage_percent=0.0,
            success=route_appropriate
        )
        
        test_result = TestResult.PASS if route_appropriate else TestResult.FAIL
        
        self.record_test_result(test_case, test_result, metrics=metrics,
                              details={
                                  "route_appropriate": route_appropriate,
                                  "quality_assessment": quality_assessment,
                                  "performance_ok": performance_ok,
                                  "reasoning_provided": has_reasoning
                              })
    
    async def _test_plugin_routing(self, test_case: TestCase):
        """æµ‹è¯•æ’ä»¶è·¯ç”±"""
        message = test_case.input_data["message"]
        expected_plugin = test_case.input_data.get("expected_plugin")
        max_time = test_case.input_data["max_time"]
        
        result = await self.send_chat_request(message)
        
        if "error" in result:
            self.record_test_result(test_case, TestResult.FAIL,
                                  details={"error": result["error"]})
            return
        
        content = result.get("content", "")
        model_used = result.get("model_used", "")
        reasoning = result.get("reasoning", "")
        response_time = result.get("_response_time_ms", 0)
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†æ’ä»¶
        plugin_used = False
        plugin_indicators = ["plugin", "æ’ä»¶", "è°ƒç”¨", "æŸ¥è¯¢"]
        
        if any(indicator in reasoning.lower() for indicator in plugin_indicators):
            plugin_used = True
        
        # é’ˆå¯¹ç‰¹å®šæ’ä»¶çš„éªŒè¯
        plugin_result_valid = False
        
        if expected_plugin == "weather":
            # å¤©æ°”æ’ä»¶åº”è¯¥è¿”å›å¤©æ°”ç›¸å…³ä¿¡æ¯
            weather_keywords = ["å¤©æ°”", "æ¸©åº¦", "æ¹¿åº¦", "é£", "æ™´", "é›¨", "äº‘"]
            plugin_result_valid = any(keyword in content for keyword in weather_keywords)
        
        elif expected_plugin == "system":
            # ç³»ç»Ÿæ’ä»¶åº”è¯¥è¿”å›ç³»ç»Ÿä¿¡æ¯
            system_keywords = ["CPU", "å†…å­˜", "ç£ç›˜", "è¿›ç¨‹", "%"]
            plugin_result_valid = any(keyword in content for keyword in system_keywords)
        
        else:
            # é€šç”¨æ’ä»¶éªŒè¯
            plugin_result_valid = len(content) > 20
        
        performance_ok = self.assert_performance(response_time, max_time, test_case.name)
        
        success = plugin_used and plugin_result_valid
        
        metrics = TestMetrics(
            response_time_ms=response_time,
            token_count=result.get("token_count", 0),
            model_used=model_used,
            memory_usage_mb=0.0,
            cpu_usage_percent=0.0,
            success=success
        )
        
        test_result = TestResult.PASS if success else TestResult.FAIL
        
        self.record_test_result(test_case, test_result, metrics=metrics,
                              details={
                                  "plugin_used": plugin_used,
                                  "plugin_result_valid": plugin_result_valid,
                                  "expected_plugin": expected_plugin,
                                  "performance_ok": performance_ok
                              })
    
    async def _test_load_balance_routing(self, test_case: TestCase):
        """æµ‹è¯•è´Ÿè½½å‡è¡¡è·¯ç”±"""
        message = test_case.input_data["message"]
        max_time = test_case.input_data["max_time"]
        simulate_high_load = test_case.input_data.get("simulate_high_load", False)
        
        if simulate_high_load:
            # æ¨¡æ‹Ÿé«˜è´Ÿè½½ï¼šåŒæ—¶å‘é€å¤šä¸ªè¯·æ±‚
            tasks = []
            for i in range(3):
                task = asyncio.create_task(self.send_chat_request(f"{message} (è¯·æ±‚{i+1})"))
                tasks.append(task)
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # åˆ†æè´Ÿè½½å‡è¡¡æ•ˆæœ
            successful_requests = [r for r in results if isinstance(r, dict) and "error" not in r]
            failed_requests = [r for r in results if isinstance(r, Exception) or (isinstance(r, dict) and "error" in r)]
            
            if len(successful_requests) < 2:
                self.record_test_result(test_case, TestResult.FAIL,
                                      details={"error": f"é«˜è´Ÿè½½ä¸‹æˆåŠŸè¯·æ±‚è¿‡å°‘: {len(successful_requests)}/3"})
                return
            
            # æ£€æŸ¥å“åº”æ—¶é—´åˆ†å¸ƒ
            response_times = [r.get("_response_time_ms", 0) for r in successful_requests]
            avg_response_time = sum(response_times) / len(response_times)
            
            load_balanced = avg_response_time <= max_time
            
            metrics = TestMetrics(
                response_time_ms=int(avg_response_time),
                token_count=sum(r.get("token_count", 0) for r in successful_requests),
                model_used="load_balanced",
                memory_usage_mb=0.0,
                cpu_usage_percent=0.0,
                success=load_balanced
            )
            
            test_result = TestResult.PASS if load_balanced else TestResult.FAIL
            
            self.record_test_result(test_case, test_result, metrics=metrics,
                                  details={
                                      "successful_requests": len(successful_requests),
                                      "failed_requests": len(failed_requests),
                                      "avg_response_time": avg_response_time,
                                      "load_balanced": load_balanced
                                  })
        
        else:
            # æ™®é€šè´Ÿè½½å‡è¡¡æµ‹è¯•
            result = await self.send_chat_request(message)
            
            if "error" in result:
                self.record_test_result(test_case, TestResult.FAIL,
                                      details={"error": result["error"]})
                return
            
            response_time = result.get("_response_time_ms", 0)
            performance_ok = self.assert_performance(response_time, max_time, test_case.name)
            
            metrics = TestMetrics(
                response_time_ms=response_time,
                token_count=result.get("token_count", 0),
                model_used=result.get("model_used", ""),
                memory_usage_mb=0.0,
                cpu_usage_percent=0.0,
                success=performance_ok
            )
            
            test_result = TestResult.PASS if performance_ok else TestResult.FAIL
            
            self.record_test_result(test_case, test_result, metrics=metrics,
                                  details={"performance_ok": performance_ok})
    
    async def _test_resource_constraint_routing(self, test_case: TestCase):
        """æµ‹è¯•èµ„æºçº¦æŸä¸‹çš„è·¯ç”±å†³ç­–"""
        message = test_case.input_data["message"]
        max_time = test_case.input_data["max_time"]
        
        # è·å–ç³»ç»ŸçŠ¶æ€
        system_status = await self.get_system_status()
        
        result = await self.send_chat_request(message)
        
        if "error" in result:
            self.record_test_result(test_case, TestResult.FAIL,
                                  details={"error": result["error"]})
            return
        
        model_used = result.get("model_used", "")
        reasoning = result.get("reasoning", "")
        response_time = result.get("_response_time_ms", 0)
        
        # æ£€æŸ¥æ˜¯å¦è€ƒè™‘äº†èµ„æºçº¦æŸ
        resource_aware = False
        if "èµ„æº" in reasoning or "è´Ÿè½½" in reasoning or "æ€§èƒ½" in reasoning:
            resource_aware = True
        
        # åœ¨èµ„æºå—é™æƒ…å†µä¸‹ï¼Œåº”è¯¥é€‰æ‹©æ›´é«˜æ•ˆçš„è·¯ç”±
        efficient_route = True
        if response_time > max_time * 1.5:  # å…è®¸ä¸€å®šçš„æ—¶é—´å»¶é•¿
            efficient_route = False
        
        performance_ok = self.assert_performance(response_time, max_time, test_case.name)
        
        success = resource_aware and efficient_route
        
        metrics = TestMetrics(
            response_time_ms=response_time,
            token_count=result.get("token_count", 0),
            model_used=model_used,
            memory_usage_mb=0.0,
            cpu_usage_percent=0.0,
            success=success
        )
        
        test_result = TestResult.PASS if success else TestResult.FAIL
        
        self.record_test_result(test_case, test_result, metrics=metrics,
                              details={
                                  "resource_aware": resource_aware,
                                  "efficient_route": efficient_route,
                                  "performance_ok": performance_ok,
                                  "system_status": system_status
                              })
    
    async def run_routing_tests(self):
        """è¿è¡Œæ‰€æœ‰è·¯ç”±å†³ç­–æµ‹è¯•"""
        self.logger.info("ğŸ§­ å¼€å§‹æ™ºèƒ½è·¯ç”±å†³ç­–éªŒè¯æµ‹è¯•")
        await self.run_all_tests(self.routing_test_cases)


async def main():
    """ä¸»å‡½æ•°"""
    test_suite = IntelligentRoutingTestSuite()
    
    try:
        await test_suite.run_routing_tests()
    except KeyboardInterrupt:
        test_suite.logger.info("æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        test_suite.logger.error(f"è·¯ç”±æµ‹è¯•è¿è¡Œå¼‚å¸¸: {e}")


if __name__ == "__main__":
    asyncio.run(main())