# 部署与运维配置

<cite>
**本文档引用的文件**   
- [build.sh](file://scripts/build.sh)
- [run_server.sh](file://scripts/run_server.sh)
- [CMakeLists.txt](file://CMakeLists.txt)
- [cpp/CMakeLists.txt](file://cpp/CMakeLists.txt)
- [python/main.py](file://python/main.py)
- [python/agent/orchestrator.py](file://python/agent/orchestrator.py)
- [python/models/schemas.py](file://python/models/schemas.py)
- [python/agent/api_router.py](file://python/agent/api_router.py)
- [deployment/docker/Dockerfile](file://deployment/docker/Dockerfile)
</cite>

## 目录
1. [编译与构建流程](#编译与构建流程)  
2. [服务启动与参数调优](#服务启动与参数调优)  
3. [环境变量控制系统行为](#环境变量控制系统行为)  
4. [容器化部署建议](#容器化部署建议)  
5. [健康检查接口集成](#健康检查接口集成)  
6. [日志收集方案](#日志收集方案)  
7. [性能压测与资源预估](#性能压测与资源预估)

## 编译与构建流程

本项目采用 `CMake` 作为 C++ 模块的构建系统，通过 `build.sh` 脚本统一管理整个项目的编译、依赖安装和测试流程。

### C++模块编译选项配置

在 `CMakeLists.txt` 文件中定义了核心编译参数：

- **C++标准**: 使用 C++20 标准（`set(CMAKE_CXX_STANDARD 20)`），确保支持现代语言特性。
- **编译模式**: 
  - Release 模式启用 `-O3` 优化并定义 `NDEBUG` 宏以关闭调试断言。
  - Debug 模式包含调试信息 `-g` 并禁用优化 `-O0`。
- **依赖查找**: 通过 `find_package(Protobuf REQUIRED)` 和 `find_package(gRPC REQUIRED)` 自动定位 Protobuf 和 gRPC 库，确保协议序列化和远程调用功能正常工作。
- **链接方式**: 在 `cpp/CMakeLists.txt` 中使用 `target_link_libraries` 显式链接 `gRPC::grpc++` 和 `protobuf::libprotobuf`，保证符号正确解析。

GPU加速已在代码中实现。`cpp/CMakeLists.txt` 中通过 `find_package(CUDA QUIET)` 查找CUDA，并在找到时启用GPU加速：
```cmake
find_package(CUDA QUIET)
if(CUDA_FOUND)
    enable_language(CUDA)
    add_definitions(-DENABLE_CUDA)
    message(STATUS "CUDA found, enabling GPU acceleration")
else()
    message(STATUS "CUDA not found, GPU acceleration disabled")
endif()
```

此外，`scripts/deploy_performance_optimization.sh` 脚本会自动检测 `nvcc` 是否可用，并在CMake配置中添加 `-DENABLE_CUDA=ON` 选项来启用CUDA支持。

### 构建脚本执行流程

`scripts/build.sh` 提供了完整的构建流水线：

1. **依赖检查**: 验证 `cmake`, `python3`, `pip3` 等是否已安装，并检查版本要求（CMake >= 3.20, Python >= 3.9）。
2. **目录设置**: 创建 `build/` 目录用于存放中间产物，实现源码隔离。
3. **C++编译**: 执行 `cmake ..` 配置项目，并调用 `make -j$(nproc)` 多线程编译，最后运行 `make install` 将产出物复制到 `install/` 目录。
4. **Python依赖安装**: 使用 `pip3 install -r requirements.txt` 安装 Python 第三方库。可选参数 `--venv` 可创建独立虚拟环境避免依赖冲突。
5. **自动化测试**: 若未指定 `--skip-tests`，则自动运行 C++ 单元测试和 Python 测试（`pytest tests/`）。

该脚本支持以下命令行参数：
- `--build-type`: 构建类型 (Debug|Release|RelWithDebInfo)，默认为Release。
- `--jobs N`: 并行编译任务数，默认为CPU核心数。
- `--clean`: 清理旧构建文件。
- `--ninja`: 使用Ninja构建系统替代Make。
- `--venv`: 启用 Python 虚拟环境。
- `--skip-tests`: 跳过测试阶段，加快构建速度。
- `--coverage`: 启用代码覆盖率分析。
- `--sanitizers`: 启用地址和未定义行为检测器。
- `--help`: 查看帮助信息。

**Section sources**
- [build.sh](file://scripts/build.sh) - *更新了构建选项和错误处理*
- [CMakeLists.txt](file://CMakeLists.txt) - *增加了构建类型支持*
- [cpp/CMakeLists.txt](file://cpp/CMakeLists.txt) - *添加了CUDA支持检测*

## 服务启动与参数调优

服务由 `run_server.sh` 脚本启动，采用分层架构：C++ 后端提供高性能计算能力，Python 前端暴露 REST API 接口。

### 启动流程分析

1. **目录初始化**: 自动创建 `logs/`, `data/`, `python/plugins/`, `run/` 等必要目录。
2. **端口检测**: 使用 `lsof` 检查 gRPC（默认 50051）和 HTTP（默认 8000）端口是否被占用，若存在冲突则提示用户选择终止现有进程或退出。
3. **C++后端启动**: 以前台守护进程方式运行 `ai_assistant_server`，输出重定向至 `logs/grpc_server.log`。启动后等待 3 秒并通过 PID 检查确认进程存活。
4. **Python前端启动**: 进入 `python/` 目录，设置环境变量后调用 `uvicorn` 启动 FastAPI 服务。

### 启动参数调优

`run_server.sh` 支持以下关键参数进行性能调优：

| 参数 | 默认值 | 说明 |
|------|--------|------|
| `--host` | 0.0.0.0 | 绑定的网络接口地址 |
| `--port` | 8000 | HTTP API 服务端口 |
| `--grpc-port` | 50051 | gRPC 内部通信端口 |
| `--workers` | 4 | uvicorn工作进程数 |
| `--log-level` | INFO | 日志输出级别（DEBUG/INFO/WARNING/ERROR） |
| `--health-timeout` | 30 | 健康检查超时时间(秒) |
| `--startup-wait` | 5 | 服务启动等待时间(秒) |

在生产环境中，Python API 服务使用 `--workers 4` 启动多个工作进程，充分利用多核 CPU。此数值可根据服务器核心数适当调整，一般建议设置为 CPU 核心数或其 2 倍。

此外，可通过环境变量进一步控制行为：
- `GRPC_SERVER_ADDRESS`: 指定 C++ 服务地址，便于微服务部署场景。
- `DEBUG`: 控制是否启用开发模式。
- `LOG_LEVEL`: 动态调整日志详细程度。

**Section sources**
- [run_server.sh](file://scripts/run_server.sh) - *增强了参数解析和健康检查功能*
- [python/main.py](file://python/main.py) - *保持不变*

## 环境变量控制系统行为

系统通过环境变量实现灵活的行为控制，无需修改代码即可适应不同部署环境。

### 模型优先级切换

虽然当前代码中未直接体现本地/云端模型优先级的环境变量控制，但在 `IntelligentRouter` 类中存在决策策略字段，其路由配置包括 `local_preference`, `cost_weight`, `performance_weight` 等权重参数，可以根据系统负载动态调整路由决策。

可通过扩展 `run_server.sh` 脚本，在启动时读取环境变量 `MODEL_ROUTING_STRATEGY` 并传递给 Python 服务来实现动态切换。

### 日志级别调整

日志级别由 `LOG_LEVEL` 环境变量控制，影响 C++ 和 Python 两部分：

- **C++侧**: 通过 `--log-level=$LOG_LEVEL` 传递给 `ai_assistant_server`，内部使用标准日志库输出。
- **Python侧**: 通过 `--log-level $(echo $LOG_LEVEL | tr '[:upper:]' '[:lower:]')` 转换为小写后传给 `uvicorn`，兼容其日志系统。

支持的日志级别包括：`DEBUG`, `INFO`, `WARNING`, `ERROR`, `CRITICAL`。生产环境推荐使用 `INFO` 或更高层级以减少 I/O 开销。

**Section sources**
- [run_server.sh](file://scripts/run_server.sh) - *增强了环境变量处理*
- [python/core/intelligent_router.py](file://python/core/intelligent_router.py) - *智能路由配置*
- [python/main.py](file://python/main.py) - *保持不变*

## 容器化部署建议

### Dockerfile 建议

基于当前构建逻辑，`deployment/docker/Dockerfile` 已经提供了优化的多阶段构建方案：

```dockerfile
# 构建阶段
FROM ubuntu:22.04 AS builder
# ... 构建依赖安装和编译 ...

# 运行阶段
FROM ubuntu:22.04 AS runtime
# ... 运行时依赖安装 ...
COPY --from=builder /app/install/ ./install/
COPY --from=builder /usr/local/lib/python3.10/dist-packages/ /usr/local/lib/python3.10/dist-packages/
# ... 其他应用文件复制 ...

# 健康检查
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# 启动脚本
ENTRYPOINT ["docker-entrypoint.sh"]
CMD ["server"]
```

构建镜像：
```bash
docker build -t ai-assistant .
```

运行容器：
```bash
docker run -d -p 8000:8000 -p 50051:50051 \
  -e LOG_LEVEL=INFO \
  --name assistant-container ai-assistant
```

### Kubernetes 集成思路

建议将 C++ 和 Python 服务拆分为两个独立的 Deployment，通过 Service 实现内部通信：

1. **gRPC服务部署**:
   - 使用 `Deployment` 部署 C++ 模块。
   - 通过 Headless Service 提供稳定 DNS 记录。
   - 可结合 Node Affinity 调度到具备 GPU 的节点。

2. **API网关部署**:
   - 使用 `Deployment` 部署 Python 服务，副本数根据负载弹性伸缩。
   - 配置 `GRPC_SERVER_ADDRESS` 指向 gRPC 服务的 ClusterIP。
   - 使用 Ingress 对外暴露 HTTPS 接口。

3. **配置管理**:
   - 使用 ConfigMap 存储 `settings` 配置。
   - 使用 Secret 管理敏感信息（如插件 API Key）。
   - 利用 Downward API 注入 Pod 元数据。

4. **监控与自愈**:
   - 配置 Liveness/Readiness 探针对接 `/health` 接口。
   - 结合 Prometheus 抓取指标，实现自动告警与扩缩容。

`deployment/k8s/deploy.sh` 脚本提供了完整的Kubernetes部署解决方案，支持部署、清理、验证等功能，并可通过环境变量控制命名空间、环境和镜像标签。

**Section sources**
- [deployment/docker/Dockerfile](file://deployment/docker/Dockerfile) - *新增的Dockerfile，支持多阶段构建*
- [deployment/k8s/deploy.sh](file://deployment/k8s/deploy.sh) - *Kubernetes部署脚本*

## 健康检查接口集成

系统已内置多层次健康检查机制，保障服务稳定性。

### 健康检查接口

- **HTTP健康检查**: `GET /health` 返回 JSON 格式的组件状态，包括 `grpc_client` 和 `orchestrator` 的连通性。
- **系统状态接口**: `GET /system/status` 提供详细的资源使用情况，如 CPU、内存、GPU 使用率及各组件健康状态。

这些接口由 `python/main.py` 和 `api_router.py` 实现，利用 FastAPI 的依赖注入机制获取运行时实例并执行探测。

### 脚本级健康检查

`run_server.sh` 中的 `health_check()` 函数在服务启动后自动执行：
1. 使用 `nc -z` 检查 gRPC 端口是否监听。
2. 使用 `curl` 请求 `/health` 端点验证 HTTP 服务可用性。
3. 检查系统资源使用情况（内存、磁盘）。

只有所有检查均通过才会认为服务健康。健康检查结果会以彩色摘要形式显示，便于快速识别问题。

**Section sources**
- [run_server.sh](file://scripts/run_server.sh) - *增强了健康检查功能，包括系统资源监控*
- [python/unified_api_gateway.py](file://python/core/unified_api_gateway.py) - *健康检查实现*

## 日志收集方案

系统采用多层次日志收集方案，确保日志的完整性和可追溯性。

### 日志配置

`configs/logging.yaml` 定义了详细的日志配置：
- **格式**: 支持标准、详细和JSON格式。
- **处理器**: 包括控制台输出、文件轮转（10MB大小限制，保留5个备份）和错误专用文件。
- **日志级别**: 不同组件可配置不同级别，如 `ai_assistant` 为DEBUG，`uvicorn` 为INFO。

### 集中式日志收集

`deployment/monitoring` 目录提供了完整的日志收集方案：
- **Loki**: 日志聚合系统，存储结构化日志。
- **Promtail**: 日志收集代理，从各个来源采集日志并发送到Loki。
- **Grafana**: 日志可视化和查询界面。

`deployment/monitoring/promtail/promtail.yml` 配置了多种日志源：
- NEX应用日志（JSON格式）
- 系统日志（syslog）
- Docker容器日志
- Nginx访问和错误日志

通过 `docker-compose.yml` 可以一键启动整个监控栈，实现日志的集中管理和分析。

**Section sources**
- [configs/logging.yaml](file://configs/logging.yaml) - *日志配置文件*
- [deployment/monitoring/promtail/promtail.yml](file://deployment/monitoring/promtail/promtail.yml) - *Promtail日志收集配置*
- [deployment/monitoring/docker-compose.yml](file://deployment/monitoring/docker-compose.yml) - *监控组件编排*

## 性能压测与资源预估

### 性能压测建议

1. **基准测试**: 使用 `tests/unit/test_resource_management.py` 中的测试套件进行系统监控精度测试。
2. **并发测试**: 模拟高并发请求，测试系统的吞吐量和响应时间。
3. **压力测试**: 持续施加压力，观察系统在长时间高负载下的表现。
4. **边界测试**: 测试系统在资源极限情况下的行为和恢复能力。

### 资源消耗预估

根据系统架构和组件特性，资源消耗主要集中在以下几个方面：
- **CPU**: C++推理引擎和Python API处理是主要CPU消耗者。
- **内存**: 模型加载和缓存需要大量内存，建议至少16GB RAM。
- **GPU**: 如果启用CUDA加速，需要相应显存支持模型运行。
- **磁盘I/O**: 日志记录和模型持久化会产生磁盘I/O。

建议在生产环境中预留足够的资源余量，并配置相应的监控和告警机制。

**Section sources**
- [tests/unit/test_resource_management.py](file://tests/unit/test_resource_management.py) - *资源管理测试套件*
- [PROJECT_STRUCTURE_REPORT.md](file://PROJECT_STRUCTURE_REPORT.md) - *项目结构报告*